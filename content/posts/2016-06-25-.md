---
title: Policing Your URLs with WWW::RoboCop
author: oalders
type: post
date: -001-11-30T00:00:00+00:00
draft: true
url: /2016-06-25-
categories:
  - Uncategorized

---
A while back I was looking around CPAN for various solutions that implement web site crawlers. I couldn't find one that suited my needs exactly. I just wanted a simple robot that wouldn't visit an URL twice but that also gave me easy way to whitelist or blacklist URLs. I did find one module (can't remember which) that did this using regexes, but that was going to be way too complicated. So, I put my own simple module together. I give you [https://metacpan.org/pod/WWW::RoboCop][1].

 [1]: http://WWW::RoboCop
